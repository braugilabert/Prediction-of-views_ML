{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <<<<<<<<<<<<<<<<< MODELOS >>>>>>>>>>>>>>>>>>>>>>>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERAR ARCHIVOS DE TRAIN Y TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/processed.csv')\n",
    "train, test = train_test_split(df, test_size=0.33, shuffle=True) # Pronto llegará la 33\n",
    "\n",
    "train.to_csv('../data/train.csv', index=False)\n",
    "test.to_csv('../data/test.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LOGISTIC REGRESSION (me falta el cross validation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hands on Machine Learning: \"Just like a Linear Regression model, a Logistic Regression model computes a weighted sum of the input features (plus a bias term), but instead of outputting the result directly like the Linear Regression model does, it outputs the logistic of this result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "train.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTORAS Y TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['Visualizaciones', 'Título del vídeo'])\n",
    "y = train['Visualizaciones']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARACIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test) #predicciones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test.drop(columns=['Visualizaciones', 'Título del vídeo'])\n",
    "y = test['Visualizaciones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_finales = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para hacer el dataframe final\n",
    "DTpredicciones = pd.DataFrame(predicciones_finales)\n",
    "DTpredicciones.reset_index(drop=True, inplace=True) #para que se quiten los indices\n",
    "id = test.loc[:, ['Título del vídeo']]\n",
    "id.reset_index(drop=True, inplace=True)\n",
    "df_unido = id.join(DTpredicciones) #unir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido.columns = ['Título del vídeo', 'Visualizaciones'] #para poner el nombre a las columnas\n",
    "df_unido['Visualizaciones'] = df_unido['Visualizaciones'].round(0).astype('int') #para redondear las visualizaciones y poner la columna en números enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_unido.to_csv('siralatriste_submission.csv', index=False) #para pasar el dataframe a csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARA GUARDAR EL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../models/modelo_LR.pkl', 'wb') as archivo:\n",
    "    pickle.dump(lr, archivo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RANDOM FOREST REGRESSOR con GradientBoostingRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hands on Machine Learning : \"Random Forests work by training many Decision Trees on random subsets of the features, then averaging out their predictions. Building a model on top of many other models is called Ensemble Learning, and it is often a great way to push ML algorithms even further\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed.csv')\n",
    "\n",
    "\"\"\" train, test = train_test_split(df, test_size=0.33, shuffle=True) #con shuffle, que los videos estaban ordenados por visualizaciones \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" train = pd.read_csv('data/train.csv')\n",
    "train.head(1) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Visualizaciones', 'Título del vídeo'])\n",
    "y = df['Visualizaciones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=33)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor(random_state=33)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es sin cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mae"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[('model', RandomForestRegressor(n_estimators=100, random_state=33))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATION que hay que pasar al evaluation.py\n",
    "scores = -1 * cross_val_score(model_pipeline, X, y, cv=5, scoring='neg_mean_absolute_error') \n",
    "#lo multiplico por -1 para que se vea positivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../models/modelo_RFR.pkl', 'wb') as archivo:\n",
    "    pickle.dump(model, archivo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DECISION TREES (DecisionTreeRegressor junto a XGBRegressor, el cual igual quito para ponerlo por separado con el ejemplo de apuntes del test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hands On Machine Learning: \"This is a powerful model, capable of finding complex nonlinear relationships in the data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OJO QUE AQUI EMPIEZO CON TODOS LOS DATOS (data =) NO CON train =\n",
    "df = pd.read_csv('../data/processed.csv')\n",
    "df['Visualizaciones'] = df.Visualizaciones\n",
    "#data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRAFICO INTERESANTE PARA VER DE OTRA MANERA LA CORRELACION DE LAS VARIABLES (Hay que recortar las variables a las que se eligieron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # GRÁFICO PARA VER LA CORRELACION DE LAS VARIABLES\n",
    "plt.figure(figsize=(5,5))\n",
    "bars = df.corr()['Visualizaciones'].sort_values(ascending=False).plot(kind='bar') \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLIPT DEL TEST Y DEL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Visualizaciones', 'Título del vídeo'])\n",
    "y = df['Visualizaciones']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIT DEL MODELO (base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = XGBRegressor()\n",
    "model = regressor.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'Predicted views':y_pred, 'Actual views':y_test})\n",
    "\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "\n",
    "test = test.reset_index() # REVISAR ESTE PASO Y EL DE DESPUÉS\n",
    "test = test.drop(['index'],axis=1)\n",
    "\n",
    "plt.plot(test[:50]) #revisar si tengo que coger sobre 50 o más bien la mitad de los datos\n",
    "plt.legend(['Actual views','Predicted views'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATION (pasar al .py después, creo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [None, 2, 3, 4]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(\n",
    "    DecisionTreeRegressor(random_state=33),\n",
    "    cv=10,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    param_grid=param_grid\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AÑADIR UNA NUEVA FEATURE USANDO EL DECISION TREE COMBINANDO LAS 3 VARIABLES MÁS CORRELADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr().abs() #para sacarlo con valores absolutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_visual = corr.loc[:,['Visualizaciones']] #para sacar las correlaciones de Visualizaciones\n",
    "corr_visual.sort_values(ascending=False, by = 'Visualizaciones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selecc = ['Visualizaciones necesarias para suscribirse al canal', 'Porcentaje de clics de las impresiones (%)', 'Visualizaciones necesarias para compartir el video'] #seleccionar las 3 mejores\n",
    "\n",
    "model.fit(X_train[features_selecc], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridSearchCV(cv=10, estimator=DecisionTreeRegressor(random_state=11),\n",
    "             param_grid={'max_depth': [None, 2, 3, 4]},\n",
    "             scoring='neg_mean_squared_error')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict() usando el modelo de las 3 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.assign(VAR1_VAR2_VAR3=model.predict(X_train[features_selecc]))\n",
    "X_test = X_test.assign(VAR1_VAR2_VAR3=model.predict(X_test[features_selecc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RE-FIT DEL MODELO CON LA NUEVA VARIABLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = XGBRegressor()\n",
    "model = regressor.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto está copiado de arriba\n",
    "\n",
    "test = pd.DataFrame({'Predicted views':y_pred, 'Actual views':y_test})\n",
    "\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "\n",
    "test = test.reset_index() # REVISAR ESTE PASO Y EL DE DESPUÉS\n",
    "test = test.drop(['index'],axis=1)\n",
    "\n",
    "plt.plot(test[:50]) #revisar si tengo que coger sobre 50 o más bien la mitad de los datos\n",
    "plt.legend(['Actual views','Predicted views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../models/modelo_DT.pkl', 'wb') as archivo:\n",
    "    pickle.dump(model, archivo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LINEAR REGRESSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hands On Machine Learning: \"The simplest and most commonly used.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plt.figure(figsize=(14,8))\n",
    "bars = df.corr()['Visualizaciones'].sort_values(ascending=False).plot(kind='bar') \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Visualizaciones', 'Título del vídeo'])\n",
    "y = df['Visualizaciones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el momento, los datos consisten en valores pequeños y grandes. Hay algunas columnas que tienen valores medianos de más de 2650. Como estas varían tanto en tamaño, confunden en modelo. Para ponerlos todos en una escala uniforme, tengo que usar la función StandardScaler(). Es importante destacar que usamos fit_transform() en nuestros datos de X_train, pero solo usamos fit() en nuestros datos de X_test. No hacer esto puede causar una \"fuga de datos\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear el Modelo de Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "#y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Error (pasar a evaluation después)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_pred))) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MÁS EVALUACION (Pasar tb a evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'Predicted VIEWS':y_pred, 'Actual VIEWS':y_test})\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "\n",
    "test = test.reset_index()\n",
    "test = test.drop(['index'],axis=1)\n",
    "\n",
    "plt.plot(test[:40])\n",
    "plt.legend(['Actual VIEWS','Predicted VIEWS'])\n",
    "\n",
    "# MALDITOS OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../models/modelo_LinR.pkl', 'wb') as archivo:\n",
    "    pickle.dump(model, archivo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. XGBREGRESSOR CON GRIDSEARCHCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hands On Machine Learning: \"It is worth noting that an optimized implementation of Gradient Boosting is available\n",
    "in the popular python library XGBoost, which stands for Extreme Gradient Boosting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Visualizaciones']<35000,:] #quito 2 outliers para ver que tal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Visualizaciones', 'Título del vídeo'])\n",
    "y = df['Visualizaciones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = XGBRegressor()\n",
    "model = regressor.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'Predicted views':y_pred, 'Actual views':y_test})\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "test = test.reset_index()\n",
    "test = test.drop(['index'],axis=1)\n",
    "plt.plot(test[:50])\n",
    "plt.legend(['Actual views','Predicted views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params() #para ver que parametros tiene"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda de abajo se hizo el GridSearchCV, ahora comentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" param_grid = dict(\n",
    "    n_jobs=[-1],\n",
    "    learning_rate=[0.1, 0.5],\n",
    "    objective=['reg:squarederror'],\n",
    "    max_depth=[5, 10, 15], \n",
    "    n_estimators=[100, 500, 1000],\n",
    "    subsample=[0.2, 0.8, 1.0],\n",
    "    gamma=[0.05, 0.5],\n",
    "    scale_pos_weight=[0, 1],\n",
    "    reg_alpha=[0, 0.5],\n",
    "    reg_lambda=[1, 0],\n",
    ")\n",
    "\n",
    "model = XGBRegressor(random_state=1, verbosity=1)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_root_mean_squared_error',\n",
    "                           )\n",
    "\n",
    "best_model = grid_search.fit(X_train, y_train)\n",
    "print('Mejores parametros:', best_model.best_params_) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIT DE LOS MEJORES PARÁMETROS DEL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = XGBRegressor(\n",
    "    gamma=0.05,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    n_estimators=100,\n",
    "    objective='reg:squarederror',\n",
    "    subsample=0.2,\n",
    "    scale_pos_weight=0,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1\n",
    ")\n",
    "model = regressor.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, y_pred)) #EVALUATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización del modelo mejorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'Predicted value':y_pred, 'Actual value':y_test})\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "test = test.reset_index()\n",
    "test = test.drop(['index'],axis=1)\n",
    "plt.plot(test[:100])\n",
    "plt.legend(['Actual value','Predicted value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../models/modelo_XGB.pkl', 'wb') as archivo:\n",
    "    pickle.dump(model, archivo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAML por que es el mejor modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('../models/modelo_config_def.yaml', 'w') as c:\n",
    "    yaml.dump(model, c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA. TEST PARA SACAR EL MEJOR MODELO E INTENTAR MEJORARLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGAMOS EL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Visualizaciones']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUITANDO OUTLIERS (para ayudar al modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Visualizaciones']<35000,:] #quito 2 outliers para ver que tal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Visualizaciones', 'Título del vídeo'])\n",
    "y = df['Visualizaciones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=33, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalando los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECCIÓN DE MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = {\n",
    "    \"XGBRegressor\": XGBRegressor(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "    \"GaussianProcessRegressor\": GaussianProcessRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"NuSVR\": NuSVR(),\n",
    "    \"LinearSVR\": LinearSVR(),\n",
    "    \"KernelRidge\": KernelRidge(),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\":Ridge(),\n",
    "    \"Lars\": Lars(),\n",
    "    \"TheilSenRegressor\": TheilSenRegressor(),\n",
    "    \"HuberRegressor\": HuberRegressor(),\n",
    "    \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor(),\n",
    "    \"ARDRegression\": ARDRegression(),\n",
    "    \"BayesianRidge\": BayesianRidge(),\n",
    "    \"ElasticNet\": ElasticNet(),\n",
    "    \"OrthogonalMatchingPursuit\": OrthogonalMatchingPursuit(),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto de abajo recorre cada uno de los modelos, lo ajusta usando los datos de X_train y y_train, y luego genera predicciones de X_test y calcula el RMSE medio de 10 rondas de Cross Validation. Eso nos dará el RMSE para los datos de X_test, más el RMSE promedio para el conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models = pd.DataFrame(columns=['model', 'run_time', 'rmse', 'rmse_cv'])\n",
    "\n",
    "for key in regressors:\n",
    "\n",
    "    print('*',key)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    regressor = regressors[key]\n",
    "    model = regressor.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    scores = cross_val_score(model, \n",
    "                             X_train, \n",
    "                             y_train,\n",
    "                             scoring=\"neg_mean_squared_error\", \n",
    "                             cv=10)\n",
    "\n",
    "    row = {'model': key,\n",
    "           'run_time': format(round((time.time() - start_time)/60,2)),\n",
    "           'rmse': round(np.sqrt(mean_squared_error(y_test, y_pred))),\n",
    "           'rmse_cv': round(np.mean(np.sqrt(-scores)))\n",
    "    }\n",
    "\n",
    "    df_models = df_models.append(row, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abajo se ve que al ordenar los resultados del dataframe df_models, se puede ver el rendimiento de cada modelo. La puntuación RMSE de x obtenida de los modelo/s anterior/es se mejoró aquí y ahora se reduce a x. La noticia más importante es que la selección de modelos ha identificado x modelos mucho más efectivos. \n",
    "\n",
    "Al quitar los outliers, el modelo PassiveAggressiveRegressor() logró el mejor RMSE medio de 629 y el modelo HuberRegressor un RMSE de 624."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models.head(20).sort_values(by='rmse_cv', ascending=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluar el modelo de mejor rendimiento (tengo que pasarlo al evaluation.py correspondiente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = PassiveAggressiveRegressor()\n",
    "model = regressor.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'Predicted views':y_pred, 'Actual views':y_test})\n",
    "fig= plt.figure(figsize=(16,8))\n",
    "test = test.reset_index()\n",
    "test = test.drop(['index'],axis=1)\n",
    "plt.plot(test[:50])\n",
    "plt.legend(['Actual views','Predicted views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../models/modelo_RFR.pkl', 'wb') as archivo:\n",
    "    pickle.dump(model, archivo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejorar los hiperparámetros del modelo:\n",
    "\n",
    "Para ajustar el modelo PassiveAggressiveRegressor() (o cualquier modelo), hay que mirar qué hiperparámetros están disponibles para ajustar con el model.get_params()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que seleccionar algunos de los hiperparámetros y agregarlos a un dict() y asignándolos a param_grid. Luego se ejecuta la función GridSearchCV para probar cada combinación única de hiperparámetros y así encontrar los hiperparámetros óptimos del modelo. (Ahora está comentado porque ya se pensó el mejor modelo con esos parámetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" param_grid = dict(\n",
    " C= [1.0, 1.1, 1.2, 1.3],\n",
    " average= [False],\n",
    " early_stopping= [False],\n",
    " epsilon= [0.1, 0.2, 0.3],\n",
    " fit_intercept= [True],\n",
    " loss= ['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    " max_iter= [600, 800, 1000, 1200],\n",
    " n_iter_no_change= [3,5,7],\n",
    " random_state= [None],\n",
    " shuffle= [True],\n",
    " tol= [0.001, 0.002, 0.0004],\n",
    " validation_fraction= [0.1],\n",
    " verbose= [0],\n",
    " warm_start= [False])\n",
    "\n",
    "model = PassiveAggressiveRegressor(random_state=33)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='neg_root_mean_squared_error',\n",
    "                           )\n",
    "\n",
    "best_model = grid_search.fit(X_train, y_train)\n",
    "print('Best parameters:', best_model.best_params_) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIT del mejor modelo elegido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = PassiveAggressiveRegressor(C=1.1,\n",
    " average= False,\n",
    " early_stopping= False,\n",
    " epsilon= 0.1,\n",
    " fit_intercept= True,\n",
    " loss= 'epsilon_insensitive',\n",
    " max_iter= 600,\n",
    " n_iter_no_change= 7,\n",
    " random_state= None,\n",
    " shuffle= True,\n",
    " tol= 0.001,\n",
    " validation_fraction= 0.1,\n",
    " verbose= 0,\n",
    " warm_start= False)\n",
    "\n",
    "model = regressor.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('RMSE:',round(np.sqrt(mean_squared_error(y_test, y_pred))))\n",
    "print('RMSE_CV:',round(np.mean(np.sqrt(-scores)))) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESPUÉS DE 40 MINUTOS DE PENSAR, NO CONSEGUIMOS MEJORAR. EL TEST YA HABÍA DADO LA MEJOR OPCIÓN."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. [NO SUPERVISADO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [SUB] SUPPORT VECTOR MACHINE (Support Vector Regressor) [no parece que vaya a funcionar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import numpy as np\n",
    "import matplotlib.pyplot as plt \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" X = df.drop(columns=['Visualizaciones', 'Título del vídeo'])\n",
    "y = df['Visualizaciones'] \"\"\"\n",
    "\n",
    "\"\"\" X = np.sort(5*np.random.rand(200,1),axis=0)\n",
    "Y = np.sin(X).ravel()\n",
    "Y[::5] += 3*(0.5 - np.random.rand(40)) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" plt.scatter(X,y, color=\"darkorange\", label=\"data\") \"\"\"\n",
    "# ValueError: x and y must be the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "from sklearn.svm import SVR\n",
    "\n",
    "C=1e3\n",
    "\n",
    "svr_lin = SVR(kernel=\"linear\", C=C)\n",
    "svr_rbf = SVR(kernel=\"rbf\", C=C, gamma=0.1)\n",
    "svr_pol = SVR(kernel=\"poly\", C=C, degree=3) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" y_lin = svr_lin.fit(X,y).predict(X)\n",
    "y_rbf = svr_rbf.fit(X,y).predict(X)\n",
    "y_pol = svr_pol.fit(X,y).predict(X) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" lw = 2\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.scatter(X,y,color=\"darkorange\", label =\"data\")\n",
    "\n",
    "plt.plot(X,y_lin, color=\"navy\", lw = lw, label = \"SVM Lineal\")\n",
    "plt.plot(X,y_rbf, color=\"c\", lw=lw, label=\"SVM Radial\")\n",
    "plt.plot(X,y_pol, color=\"cornflowerblue\", label=\"SVM Polinómico\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "plt.title(\"Support Vector Regression\")\n",
    "plt.legend()\n",
    "plt.show() \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
